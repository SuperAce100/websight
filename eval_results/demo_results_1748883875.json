[
  {
    "task_id": "Booking--43",
    "success": false,
    "is_correct": false,
    "confidence": 0.0,
    "reasoning": "Execution failed",
    "execution_time": 280.81974744796753,
    "error": "/matx/u/tanvirb/websight/.venv/lib/python3.12/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n  warnings.warn(\n\nLoading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:00<00:00, 103.94it/s]\nUsing a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\nYou have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.\nDevice set to use cuda:0\nSetting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\nTraceback (most recent call last):\n  File \"/matx/u/tanvirb/websight/websight.py\", line 150, in <module>\n    main()\n  File \"/matx/u/tanvirb/websight/websight.py\", line 143, in main\n    if \"Error\" not in result:\n       ^^^^^^^^^^^^^^^^^^^^^\nTypeError: argument of type 'NoneType' is not iterable"
  },
  {
    "task_id": "ArXiv--22",
    "success": false,
    "is_correct": false,
    "confidence": 0.0,
    "reasoning": "Execution failed",
    "execution_time": 213.9910159111023,
    "error": "/matx/u/tanvirb/websight/.venv/lib/python3.12/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n  warnings.warn(\n\nLoading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:00<00:00, 98.21it/s]\nUsing a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\nYou have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.\nDevice set to use cuda:0\nSetting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\nTraceback (most recent call last):\n  File \"/matx/u/tanvirb/websight/websight.py\", line 150, in <module>\n    main()\n  File \"/matx/u/tanvirb/websight/websight.py\", line 143, in main\n    if \"Error\" not in result:\n       ^^^^^^^^^^^^^^^^^^^^^\nTypeError: argument of type 'NoneType' is not iterable"
  },
  {
    "task_id": "ArXiv--2",
    "success": false,
    "is_correct": false,
    "confidence": 0.0,
    "reasoning": "Execution failed",
    "execution_time": 272.2711338996887,
    "error": "/matx/u/tanvirb/websight/.venv/lib/python3.12/site-packages/transformers/utils/hub.py:111: FutureWarning: Using `TRANSFORMERS_CACHE` is deprecated and will be removed in v5 of Transformers. Use `HF_HOME` instead.\n  warnings.warn(\n\nLoading checkpoint shards:   0%|          | 0/7 [00:00<?, ?it/s]\nLoading checkpoint shards: 100%|\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 7/7 [00:00<00:00, 99.65it/s]\nUsing a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\nYou have video processor config saved in `preprocessor.json` file which is deprecated. Video processor configs should be saved in their own `video_preprocessor.json` file. You can rename the file or load and save the processor back which renames it automatically. Loading from `preprocessor.json` will be removed in v5.0.\nDevice set to use cuda:0\nSetting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\nSetting `pad_token_id` to `eos_token_id`:151645 for open-end generation.\nTraceback (most recent call last):\n  File \"/matx/u/tanvirb/websight/websight.py\", line 150, in <module>\n    main()\n  File \"/matx/u/tanvirb/websight/websight.py\", line 143, in main\n    if \"Error\" not in result:\n       ^^^^^^^^^^^^^^^^^^^^^\nTypeError: argument of type 'NoneType' is not iterable"
  }
]